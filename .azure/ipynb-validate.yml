trigger: none
pr:
  branches:
    include: [main]
  autoCancel: "true"
  drafts: "true"

# Multi-job configuration
# - https://learn.microsoft.com/en-us/azure/devops/pipelines/process/phases?view=azure-devops&tabs=yaml#multi-job-configuration

jobs:
  - job: check_diff
    pool:
      vmImage: "Ubuntu-20.04"
    steps:
      - bash: |
          set -ex
          pip install -r .actions/requires.txt
          pip list
        displayName: "Install dependencies"

      - bash: |
          git fetch --all  # some issues with missing main :/
          # head=$(git rev-parse origin/main)
          # printf "Head: $head\n"  # this shall be commit hash
          # git diff --name-only $head --output=target-diff.txt
          git diff --name-only origin/main HEAD --output=target-diff.txt
          printf "Diff to target:\n"
          cat target-diff.txt
          python .actions/assistant.py group-folders --fpath_gitdiff=target-diff.txt
          printf "Changed folders:\n"
          cat changed-folders.txt
        displayName: "Process folders"

      - bash: |
          notebooks=$(python .actions/assistant.py generate-matrix changed-folders.txt)
          echo "##vso[task.setVariable variable=dirs;isOutput=true]$notebooks"
        name: mtrx
        displayName: "Changed matrix"
      - bash: echo '$(mtrx.dirs)' | python -m json.tool
        continueOnError: "true" # not crash if the matrix is empty
        displayName: "Show matrix"

  - job: ipython
    dependsOn: check_diff
    # run if the initial job succeeded and the strategy matrix is not empty
    condition: and(succeeded(), ne(dependencies.check_diff.outputs['mtrx.dirs'], ''))
    strategy:
      matrix: $[ dependencies.check_diff.outputs['mtrx.dirs'] ]
      # Maximum number of jobs running in parallel
      maxParallel: "10"
    # how long to run the job before automatically cancelling
    timeoutInMinutes: "95"
    # how much time to give 'run always even if cancelled tasks' before stopping them
    cancelTimeoutInMinutes: "2"

    pool: $(agent-pool)
    # this need to have installed docker in the base image...
    container:
      image: $(docker-image)
      options: "--gpus=all --shm-size=32g -v /usr/bin/docker:/tmp/docker:ro"

    variables:
      ACCELERATOR: CPU,GPU
      PATH_DATASETS: "$(Build.Repository.LocalPath)/.datasets"
      DEVICES: $( python -c 'print("$(Agent.Name)".split("_")[-1])' )

    steps:
      - bash: |
          echo "##vso[task.setvariable variable=CUDA_VISIBLE_DEVICES]$(DEVICES)"
          echo "##vso[task.setvariable variable=CONTAINER_ID]$(head -1 /proc/self/cgroup|cut -d/ -f3)"
        displayName: "Set environment variables"

      - bash: |
          lspci | egrep 'VGA|3D'
          whereis nvidia
          nvidia-smi
          echo $CUDA_VISIBLE_DEVICES
          echo $CONTAINER_ID
          python --version
          pip list | grep torch
        displayName: "Image info & NVIDIA"

      - bash: |
          set -e
          pip --version
          pip install -r requirements.txt
          python .actions/assistant.py pip-install --folder=$(notebook) > notebook.txt
          pip install -r notebook.txt
        displayName: "Install dependencies"

      - bash: |
          set -ex
          pip list
          python -c "import torch ; mgpu = torch.cuda.device_count() ; assert mgpu > 0, f'GPU: {mgpu}'"
        displayName: "Sanity check"

      - bash: python .actions/assistant.py convert-ipynb --folder=$(notebook)
        displayName: "Generate notebook"

      - bash: |
          set -e
          mkdir $(PATH_DATASETS)
          python .actions/assistant.py bash-validate --folder=$(notebook)
          cat .actions/_ipynb-validate.sh
          bash .actions/_ipynb-validate.sh
        env:
          KAGGLE_USERNAME: $(KAGGLE_USERNAME)
          KAGGLE_KEY: $(KAGGLE_KEY)
        displayName: "Execute notebook"
